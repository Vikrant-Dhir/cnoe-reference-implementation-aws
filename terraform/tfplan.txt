[0m[1mkubectl_manifest.application_argocd_cert_manager: Refreshing state... [id=/apis/argoproj.io/v1alpha1/namespaces/argocd/applications/cert-manager][0m
[0m[1mkubectl_manifest.application_argocd_external_secrets: Refreshing state... [id=/apis/argoproj.io/v1alpha1/namespaces/argocd/applications/external-secrets][0m
[0m[1mkubectl_manifest.application_argocd_crossplane: Refreshing state... [id=/apis/argoproj.io/v1alpha1/namespaces/argocd/applications/crossplane][0m
[0m[1mrandom_password.keycloak_user_password: Refreshing state... [id=none][0m
[0m[1mrandom_password.keycloak_postgres_password: Refreshing state... [id=none][0m
[0m[1mrandom_password.keycloak_admin_password: Refreshing state... [id=none][0m
[0m[1mrandom_password.backstage_postgres_password: Refreshing state... [id=none][0m
[0m[1mmodule.external_secrets_role_keycloak[0].data.aws_region.current: Reading...[0m[0m
[0m[1mmodule.external_secrets_role_keycloak[0].data.aws_partition.current: Reading...[0m[0m
[0m[1mmodule.aws_load_balancer_role.data.aws_caller_identity.current: Reading...[0m[0m
[0m[1mmodule.external_secrets_role_keycloak[0].data.aws_partition.current: Read complete after 0s [id=aws][0m
[0m[1mmodule.external_secrets_role_keycloak[0].data.aws_region.current: Read complete after 0s [id=us-east-1][0m
[0m[1mmodule.data_on_eks_runner_role.data.aws_caller_identity.current: Reading...[0m[0m
[0m[1mmodule.aws_load_balancer_role.data.aws_partition.current: Reading...[0m[0m
[0m[1mmodule.aws_load_balancer_role.data.aws_partition.current: Read complete after 0s [id=aws][0m
[0m[1mmodule.data_on_eks_runner_role.data.aws_partition.current: Reading...[0m[0m
[0m[1mmodule.data_on_eks_runner_role.data.aws_partition.current: Read complete after 0s [id=aws][0m
[0m[1mmodule.crossplane_aws_provider_role.data.aws_partition.current: Reading...[0m[0m
[0m[1mmodule.crossplane_aws_provider_role.data.aws_partition.current: Read complete after 0s [id=aws][0m
[0m[1mdata.aws_eks_cluster.target: Reading...[0m[0m
[0m[1mmodule.aws_load_balancer_role.data.aws_caller_identity.current: Read complete after 0s [id=136658121779][0m
[0m[1mmodule.crossplane_aws_provider_role.data.aws_caller_identity.current: Reading...[0m[0m
[0m[1mmodule.data_on_eks_runner_role.data.aws_caller_identity.current: Read complete after 0s [id=136658121779][0m
[0m[1mmodule.data_on_eks_runner_role.data.aws_region.current: Reading...[0m[0m
[0m[1mmodule.data_on_eks_runner_role.data.aws_region.current: Read complete after 0s [id=us-east-1][0m
[0m[1mmodule.external_secrets_role_keycloak[0].data.aws_caller_identity.current: Reading...[0m[0m
[0m[1mmodule.crossplane_aws_provider_role.data.aws_caller_identity.current: Read complete after 0s [id=136658121779][0m
[0m[1mmodule.aws_load_balancer_role.data.aws_region.current: Reading...[0m[0m
[0m[1mmodule.aws_load_balancer_role.data.aws_region.current: Read complete after 0s [id=us-east-1][0m
[0m[1mdata.aws_caller_identity.current: Reading...[0m[0m
[0m[1mmodule.external_secrets_role_keycloak[0].data.aws_caller_identity.current: Read complete after 0s [id=136658121779][0m
[0m[1mmodule.crossplane_aws_provider_role.data.aws_region.current: Reading...[0m[0m
[0m[1mmodule.crossplane_aws_provider_role.data.aws_region.current: Read complete after 0s [id=us-east-1][0m
[0m[1mmodule.aws_load_balancer_role.data.aws_iam_policy_document.load_balancer_controller[0]: Reading...[0m[0m
[0m[1mdata.aws_caller_identity.current: Read complete after 0s [id=136658121779][0m
[0m[1mmodule.aws_load_balancer_role.data.aws_iam_policy_document.load_balancer_controller[0]: Read complete after 0s [id=2997734474][0m
[0m[1maws_iam_policy.external-secrets[0]: Refreshing state... [id=arn:aws:iam::136658121779:policy/cnoe-external-secrets-20240425135846995000000002][0m
[0m[1mmodule.aws_load_balancer_role.aws_iam_policy.load_balancer_controller[0]: Refreshing state... [id=arn:aws:iam::136658121779:policy/AmazonEKS_AWS_Load_Balancer_Controller-20240425135847392400000006][0m
[0m[1mdata.aws_eks_cluster.target: Read complete after 0s [id=cnoe][0m
[0m[1mdata.aws_iam_openid_connect_provider.eks_oidc: Reading...[0m[0m
[0m[1mkubectl_manifest.application_argocd_crossplane_provider: Refreshing state... [id=/apis/argoproj.io/v1alpha1/namespaces/argocd/applications/crossplane-provider][0m
[0m[1mkubectl_manifest.application_argocd_crossplane_compositions: Refreshing state... [id=/apis/argoproj.io/v1alpha1/namespaces/argocd/applications/crossplane-compositions][0m
[0m[1mdata.aws_iam_openid_connect_provider.eks_oidc: Read complete after 0s [id=arn:aws:iam::136658121779:oidc-provider/oidc.eks.us-east-1.amazonaws.com/id/180BE0CF73BE3F3F714894F131CE1A47][0m
[0m[1mmodule.aws_load_balancer_role.data.aws_iam_policy_document.this[0]: Reading...[0m[0m
[0m[1mmodule.data_on_eks_runner_role.data.aws_iam_policy_document.this[0]: Reading...[0m[0m
[0m[1mmodule.crossplane_aws_provider_role.data.aws_iam_policy_document.this[0]: Reading...[0m[0m
[0m[1mmodule.external_secrets_role_keycloak[0].data.aws_iam_policy_document.this[0]: Reading...[0m[0m
[0m[1mmodule.data_on_eks_runner_role.data.aws_iam_policy_document.this[0]: Read complete after 0s [id=235349916][0m
[0m[1mmodule.aws_load_balancer_role.data.aws_iam_policy_document.this[0]: Read complete after 0s [id=1474872904][0m
[0m[1mmodule.crossplane_aws_provider_role.data.aws_iam_policy_document.this[0]: Read complete after 0s [id=2228264634][0m
[0m[1mmodule.external_secrets_role_keycloak[0].data.aws_iam_policy_document.this[0]: Read complete after 0s [id=2340024207][0m
[0m[1mmodule.aws_load_balancer_role.aws_iam_role.this[0]: Refreshing state... [id=cnoe-aws-load-balancer-controller-20240425135847379600000005][0m
[0m[1mmodule.data_on_eks_runner_role.aws_iam_role.this[0]: Refreshing state... [id=cnoe-external-dns20240425135847192400000004][0m
[0m[1mmodule.external_secrets_role_keycloak[0].aws_iam_role.this[0]: Refreshing state... [id=cnoe-external-secrets-20240425135846996600000003][0m
[0m[1mmodule.crossplane_aws_provider_role.aws_iam_role.this[0]: Refreshing state... [id=cnoe-crossplane-provider-aws20240425135847485100000007][0m
[0m[1mmodule.aws_load_balancer_role.aws_iam_role_policy_attachment.load_balancer_controller[0]: Refreshing state... [id=cnoe-aws-load-balancer-controller-20240425135847379600000005-20240425135847767700000009][0m
[0m[1mmodule.data_on_eks_runner_role.aws_iam_role_policy_attachment.this["policy"]: Refreshing state... [id=cnoe-external-dns20240425135847192400000004-20240425135847692700000008][0m
[0m[1mkubectl_manifest.application_argocd_aws_load_balancer_controller: Refreshing state... [id=/apis/argoproj.io/v1alpha1/namespaces/argocd/applications/aws-load-balancer-controller][0m
[0m[1mkubectl_manifest.application_argocd_ingress_nginx: Refreshing state... [id=/apis/argoproj.io/v1alpha1/namespaces/argocd/applications/ingress-nginx][0m
[0m[1mmodule.crossplane_aws_provider_role.aws_iam_role_policy_attachment.this["policy"]: Refreshing state... [id=cnoe-crossplane-provider-aws20240425135847485100000007-2024042513584788260000000a][0m
[0m[1mkubectl_manifest.crossplane_provider_controller_config: Refreshing state... [id=/apis/pkg.crossplane.io/v1alpha1/controllerconfigs/provider-aws-config][0m
[0m[1mkubectl_manifest.cluster_issuer_prod: Refreshing state... [id=/apis/cert-manager.io/v1/clusterissuers/letsencrypt-prod][0m
[0m[1mkubernetes_manifest.namespace_keycloak[0]: Refreshing state...[0m
[0m[1mkubernetes_manifest.serviceaccount_external_secret_keycloak[0]: Refreshing state...[0m
[0m[1mkubectl_manifest.keycloak_secret_store: Refreshing state... [id=/apis/external-secrets.io/v1beta1/namespaces/keycloak/secretstores/keycloak][0m
[0m[1mkubectl_manifest.application_argocd_keycloak: Refreshing state... [id=/apis/argoproj.io/v1alpha1/namespaces/argocd/applications/keycloak][0m

Terraform used the selected providers to generate the following execution
plan. Resource actions are indicated with the following symbols:
  [32m+[0m create[0m
  [33m~[0m update in-place[0m
[31m-[0m/[32m+[0m destroy and then create replacement[0m

Terraform will perform the following actions:

[1m  # aws_secretsmanager_secret.keycloak_config[0][0m will be created
[0m  [32m+[0m[0m resource "aws_secretsmanager_secret" "keycloak_config" {
      [32m+[0m[0m arn                            = (known after apply)
      [32m+[0m[0m description                    = "for use with cnoe keycloak installation"
      [32m+[0m[0m force_overwrite_replica_secret = false
      [32m+[0m[0m id                             = (known after apply)
      [32m+[0m[0m name                           = "cnoe/keycloak/config"
      [32m+[0m[0m name_prefix                    = (known after apply)
      [32m+[0m[0m policy                         = (known after apply)
      [32m+[0m[0m recovery_window_in_days        = 0
      [32m+[0m[0m tags_all                       = {
          [32m+[0m[0m "env"     = "dev"
          [32m+[0m[0m "project" = "cnoe"
        }
    }

[1m  # aws_secretsmanager_secret_version.keycloak_config[0][0m will be created
[0m  [32m+[0m[0m resource "aws_secretsmanager_secret_version" "keycloak_config" {
      [32m+[0m[0m arn            = (known after apply)
      [32m+[0m[0m id             = (known after apply)
      [32m+[0m[0m secret_id      = (known after apply)
      [32m+[0m[0m secret_string  = (sensitive value)
      [32m+[0m[0m version_id     = (known after apply)
      [32m+[0m[0m version_stages = (known after apply)
    }

[1m  # kubectl_manifest.application_argocd_argo_workflows[0m will be created
[0m  [32m+[0m[0m resource "kubectl_manifest" "application_argocd_argo_workflows" {
      [32m+[0m[0m api_version             = "argoproj.io/v1alpha1"
      [32m+[0m[0m apply_only              = false
      [32m+[0m[0m field_manager           = "kubectl"
      [32m+[0m[0m force_conflicts         = false
      [32m+[0m[0m force_new               = false
      [32m+[0m[0m id                      = (known after apply)
      [32m+[0m[0m kind                    = "Application"
      [32m+[0m[0m live_manifest_incluster = (sensitive value)
      [32m+[0m[0m live_uid                = (known after apply)
      [32m+[0m[0m name                    = "argo-workflows"
      [32m+[0m[0m namespace               = "argocd"
      [32m+[0m[0m server_side_apply       = false
      [32m+[0m[0m uid                     = (known after apply)
      [32m+[0m[0m validate_schema         = true
      [32m+[0m[0m wait_for_rollout        = true
      [32m+[0m[0m yaml_body               = (sensitive value)
      [32m+[0m[0m yaml_body_parsed        = <<-EOT
            apiVersion: argoproj.io/v1alpha1
            kind: Application
            metadata:
              finalizers:
              - resources-finalizer.argocd.argoproj.io
              labels:
                env: dev
              name: argo-workflows
              namespace: argocd
            spec:
              destination:
                namespace: argo
                server: https://kubernetes.default.svc
              project: cnoe
              sources:
              - chart: argo-workflows
                helm:
                  parameters:
                  - name: server.sso.issuer
                    value: https://keycloak.svc.cluster.local/realms/cnoe
                  - name: server.sso.redirectUrl
                    value: https://argo.svc.cluster.local/oauth2/callback
                  releaseName: argo-workflows
                  valueFiles:
                  - $values/packages/argo-workflows/dev/values.yaml
                repoURL: https://argoproj.github.io/argo-helm
                targetRevision: 0.31.0
              - ref: values
                repoURL: https://github.com/Vikrant-Dhir/cnoe-reference-implementation-aws
                targetRevision: HEAD
              syncPolicy:
                automated: {}
                syncOptions:
                - CreateNamespace=true
        EOT
      [32m+[0m[0m yaml_incluster          = (sensitive value)
    }

[1m  # kubectl_manifest.application_argocd_argo_workflows_sso_config[0m will be created
[0m  [32m+[0m[0m resource "kubectl_manifest" "application_argocd_argo_workflows_sso_config" {
      [32m+[0m[0m api_version             = "argoproj.io/v1alpha1"
      [32m+[0m[0m apply_only              = false
      [32m+[0m[0m field_manager           = "kubectl"
      [32m+[0m[0m force_conflicts         = false
      [32m+[0m[0m force_new               = false
      [32m+[0m[0m id                      = (known after apply)
      [32m+[0m[0m kind                    = "Application"
      [32m+[0m[0m live_manifest_incluster = (sensitive value)
      [32m+[0m[0m live_uid                = (known after apply)
      [32m+[0m[0m name                    = "argo-workflows-sso-config"
      [32m+[0m[0m namespace               = "argocd"
      [32m+[0m[0m server_side_apply       = false
      [32m+[0m[0m uid                     = (known after apply)
      [32m+[0m[0m validate_schema         = true
      [32m+[0m[0m wait_for_rollout        = true
      [32m+[0m[0m yaml_body               = (sensitive value)
      [32m+[0m[0m yaml_body_parsed        = <<-EOT
            apiVersion: argoproj.io/v1alpha1
            kind: Application
            metadata:
              finalizers:
              - resources-finalizer.argocd.argoproj.io
              labels:
                env: dev
              name: argo-workflows-sso-config
              namespace: argocd
            spec:
              destination:
                namespace: argo
                server: https://kubernetes.default.svc
              project: cnoe
              sources:
              - path: packages/argo-workflows-sso-config/dev
                repoURL: https://github.com/Vikrant-Dhir/cnoe-reference-implementation-aws
                targetRevision: HEAD
              syncPolicy:
                automated: {}
                syncOptions:
                - CreateNamespace=true
        EOT
      [32m+[0m[0m yaml_incluster          = (sensitive value)
    }

[1m  # kubectl_manifest.application_argocd_argo_workflows_templates[0m will be created
[0m  [32m+[0m[0m resource "kubectl_manifest" "application_argocd_argo_workflows_templates" {
      [32m+[0m[0m api_version             = "argoproj.io/v1alpha1"
      [32m+[0m[0m apply_only              = false
      [32m+[0m[0m field_manager           = "kubectl"
      [32m+[0m[0m force_conflicts         = false
      [32m+[0m[0m force_new               = false
      [32m+[0m[0m id                      = (known after apply)
      [32m+[0m[0m kind                    = "Application"
      [32m+[0m[0m live_manifest_incluster = (sensitive value)
      [32m+[0m[0m live_uid                = (known after apply)
      [32m+[0m[0m name                    = "argo-workflows-templates"
      [32m+[0m[0m namespace               = "argocd"
      [32m+[0m[0m server_side_apply       = false
      [32m+[0m[0m uid                     = (known after apply)
      [32m+[0m[0m validate_schema         = true
      [32m+[0m[0m wait_for_rollout        = true
      [32m+[0m[0m yaml_body               = (sensitive value)
      [32m+[0m[0m yaml_body_parsed        = <<-EOT
            apiVersion: argoproj.io/v1alpha1
            kind: Application
            metadata:
              finalizers:
              - resources-finalizer.argocd.argoproj.io
              labels:
                env: dev
              name: argo-workflows-templates
              namespace: argocd
            spec:
              destination:
                namespace: argo
                server: https://kubernetes.default.svc
              project: cnoe
              sources:
              - path: packages/argo-workflows-templates/dev/
                repoURL: https://github.com/Vikrant-Dhir/cnoe-reference-implementation-aws
                targetRevision: HEAD
              syncPolicy:
                automated: {}
                syncOptions:
                - CreateNamespace=true
        EOT
      [32m+[0m[0m yaml_incluster          = (sensitive value)
    }

[1m  # kubectl_manifest.application_argocd_aws_load_balancer_controller[0m will be updated in-place
[0m  [33m~[0m[0m resource "kubectl_manifest" "application_argocd_aws_load_balancer_controller" {
        id                      = "/apis/argoproj.io/v1alpha1/namespaces/argocd/applications/aws-load-balancer-controller"
        name                    = "aws-load-balancer-controller"
      [33m~[0m[0m yaml_incluster          = (sensitive value)
        [90m# (15 unchanged attributes hidden)[0m[0m
    }

[1m  # kubectl_manifest.application_argocd_backstage[0m will be created
[0m  [32m+[0m[0m resource "kubectl_manifest" "application_argocd_backstage" {
      [32m+[0m[0m api_version             = "argoproj.io/v1alpha1"
      [32m+[0m[0m apply_only              = false
      [32m+[0m[0m field_manager           = "kubectl"
      [32m+[0m[0m force_conflicts         = false
      [32m+[0m[0m force_new               = false
      [32m+[0m[0m id                      = (known after apply)
      [32m+[0m[0m kind                    = "Application"
      [32m+[0m[0m live_manifest_incluster = (sensitive value)
      [32m+[0m[0m live_uid                = (known after apply)
      [32m+[0m[0m name                    = "backstage"
      [32m+[0m[0m namespace               = "argocd"
      [32m+[0m[0m server_side_apply       = false
      [32m+[0m[0m uid                     = (known after apply)
      [32m+[0m[0m validate_schema         = true
      [32m+[0m[0m wait_for_rollout        = true
      [32m+[0m[0m yaml_body               = (sensitive value)
      [32m+[0m[0m yaml_body_parsed        = <<-EOT
            apiVersion: argoproj.io/v1alpha1
            kind: Application
            metadata:
              finalizers:
              - resources-finalizer.argocd.argoproj.io
              labels:
                env: dev
              name: backstage
              namespace: argocd
            spec:
              destination:
                namespace: backstage
                server: https://kubernetes.default.svc
              ignoreDifferences:
              - jsonPointers:
                - /data/k8s-config.yaml
                kind: Secret
                name: k8s-config
                namespace: backstage
              project: cnoe
              sources:
              - path: packages/backstage/dev/
                repoURL: https://github.com/Vikrant-Dhir/cnoe-reference-implementation-aws
                targetRevision: HEAD
              syncPolicy:
                automated: {}
                syncOptions:
                - CreateNamespace=true
                - RespectIgnoreDifferences=true
        EOT
      [32m+[0m[0m yaml_incluster          = (sensitive value)
    }

[1m  # kubectl_manifest.application_argocd_crossplane_compositions[0m will be updated in-place
[0m  [33m~[0m[0m resource "kubectl_manifest" "application_argocd_crossplane_compositions" {
        id                      = "/apis/argoproj.io/v1alpha1/namespaces/argocd/applications/crossplane-compositions"
        name                    = "crossplane-compositions"
      [33m~[0m[0m yaml_incluster          = (sensitive value)
        [90m# (15 unchanged attributes hidden)[0m[0m
    }

[1m  # kubectl_manifest.application_argocd_crossplane_provider[0m will be updated in-place
[0m  [33m~[0m[0m resource "kubectl_manifest" "application_argocd_crossplane_provider" {
        id                      = "/apis/argoproj.io/v1alpha1/namespaces/argocd/applications/crossplane-provider"
        name                    = "crossplane-provider"
      [33m~[0m[0m yaml_incluster          = (sensitive value)
        [90m# (15 unchanged attributes hidden)[0m[0m
    }

[1m  # kubectl_manifest.application_argocd_keycloak[0m is tainted, so must be [1m[31mreplaced[0m
[0m[31m-[0m/[32m+[0m[0m resource "kubectl_manifest" "application_argocd_keycloak" {
      [33m~[0m[0m id                      = "/apis/argoproj.io/v1alpha1/namespaces/argocd/applications/keycloak" -> (known after apply)
      [33m~[0m[0m live_manifest_incluster = (sensitive value)
      [33m~[0m[0m live_uid                = "3d65ede7-edf2-46cd-955f-862a056d8f31" -> (known after apply)
        name                    = "keycloak"
      [33m~[0m[0m uid                     = "3d65ede7-edf2-46cd-955f-862a056d8f31" -> (known after apply)
      [33m~[0m[0m yaml_incluster          = (sensitive value)
        [90m# (12 unchanged attributes hidden)[0m[0m
    }

[1m  # kubectl_manifest.ingress_argo_workflows[0m will be created
[0m  [32m+[0m[0m resource "kubectl_manifest" "ingress_argo_workflows" {
      [32m+[0m[0m api_version             = "networking.k8s.io/v1"
      [32m+[0m[0m apply_only              = false
      [32m+[0m[0m field_manager           = "kubectl"
      [32m+[0m[0m force_conflicts         = false
      [32m+[0m[0m force_new               = false
      [32m+[0m[0m id                      = (known after apply)
      [32m+[0m[0m kind                    = "Ingress"
      [32m+[0m[0m live_manifest_incluster = (sensitive value)
      [32m+[0m[0m live_uid                = (known after apply)
      [32m+[0m[0m name                    = "argo-workflows"
      [32m+[0m[0m namespace               = "argo"
      [32m+[0m[0m server_side_apply       = false
      [32m+[0m[0m uid                     = (known after apply)
      [32m+[0m[0m validate_schema         = true
      [32m+[0m[0m wait_for_rollout        = true
      [32m+[0m[0m yaml_body               = (sensitive value)
      [32m+[0m[0m yaml_body_parsed        = <<-EOT
            apiVersion: networking.k8s.io/v1
            kind: Ingress
            metadata:
              annotations:
                cert-manager.io/cluster-issuer: letsencrypt-prod
              name: argo-workflows
              namespace: argo
            spec:
              ingressClassName: nginx
              rules:
              - host: argo.svc.cluster.local
                http:
                  paths:
                  - backend:
                      service:
                        name: argo-workflows-server
                        port:
                          number: 2746
                    path: /
                    pathType: Prefix
              tls:
              - hosts:
                - argo.svc.cluster.local
                secretName: argo-workflows-prod-tls
        EOT
      [32m+[0m[0m yaml_incluster          = (sensitive value)
    }

[1m  # kubectl_manifest.ingress_backstage[0m will be created
[0m  [32m+[0m[0m resource "kubectl_manifest" "ingress_backstage" {
      [32m+[0m[0m api_version             = "networking.k8s.io/v1"
      [32m+[0m[0m apply_only              = false
      [32m+[0m[0m field_manager           = "kubectl"
      [32m+[0m[0m force_conflicts         = false
      [32m+[0m[0m force_new               = false
      [32m+[0m[0m id                      = (known after apply)
      [32m+[0m[0m kind                    = "Ingress"
      [32m+[0m[0m live_manifest_incluster = (sensitive value)
      [32m+[0m[0m live_uid                = (known after apply)
      [32m+[0m[0m name                    = "backstage"
      [32m+[0m[0m namespace               = "backstage"
      [32m+[0m[0m server_side_apply       = false
      [32m+[0m[0m uid                     = (known after apply)
      [32m+[0m[0m validate_schema         = true
      [32m+[0m[0m wait_for_rollout        = true
      [32m+[0m[0m yaml_body               = (sensitive value)
      [32m+[0m[0m yaml_body_parsed        = <<-EOT
            apiVersion: networking.k8s.io/v1
            kind: Ingress
            metadata:
              annotations:
                cert-manager.io/cluster-issuer: letsencrypt-prod
              name: backstage
              namespace: backstage
            spec:
              ingressClassName: nginx
              rules:
              - host: backstage.svc.cluster.local
                http:
                  paths:
                  - backend:
                      service:
                        name: backstage
                        port:
                          number: 7007
                    path: /
                    pathType: Prefix
              tls:
              - hosts:
                - backstage.svc.cluster.local
                secretName: backstage-prod-tls
        EOT
      [32m+[0m[0m yaml_incluster          = (sensitive value)
    }

[1m  # kubectl_manifest.ingress_keycloak[0m will be created
[0m  [32m+[0m[0m resource "kubectl_manifest" "ingress_keycloak" {
      [32m+[0m[0m api_version             = "networking.k8s.io/v1"
      [32m+[0m[0m apply_only              = false
      [32m+[0m[0m field_manager           = "kubectl"
      [32m+[0m[0m force_conflicts         = false
      [32m+[0m[0m force_new               = false
      [32m+[0m[0m id                      = (known after apply)
      [32m+[0m[0m kind                    = "Ingress"
      [32m+[0m[0m live_manifest_incluster = (sensitive value)
      [32m+[0m[0m live_uid                = (known after apply)
      [32m+[0m[0m name                    = "keycloak"
      [32m+[0m[0m namespace               = "keycloak"
      [32m+[0m[0m server_side_apply       = false
      [32m+[0m[0m uid                     = (known after apply)
      [32m+[0m[0m validate_schema         = true
      [32m+[0m[0m wait_for_rollout        = true
      [32m+[0m[0m yaml_body               = (sensitive value)
      [32m+[0m[0m yaml_body_parsed        = <<-EOT
            apiVersion: networking.k8s.io/v1
            kind: Ingress
            metadata:
              annotations:
                cert-manager.io/cluster-issuer: letsencrypt-prod
              name: keycloak
              namespace: keycloak
            spec:
              ingressClassName: nginx
              rules:
              - host: keycloak.svc.cluster.local
                http:
                  paths:
                  - backend:
                      service:
                        name: keycloak
                        port:
                          number: 8081
                    path: /realms/master
                    pathType: Prefix
                  - backend:
                      service:
                        name: keycloak
                        port:
                          number: 8081
                    path: /
                    pathType: Exact
                  - backend:
                      service:
                        name: keycloak
                        port:
                          number: 8080
                    path: /realms
                    pathType: Prefix
                  - backend:
                      service:
                        name: keycloak
                        port:
                          number: 8080
                    path: /resources
                    pathType: Prefix
              tls:
              - hosts:
                - keycloak.svc.cluster.local
                secretName: keycloak-prod-tls
        EOT
      [32m+[0m[0m yaml_incluster          = (sensitive value)
    }

[1m  # kubernetes_manifest.namespace_argo_workflows[0m will be created
[0m  [32m+[0m[0m resource "kubernetes_manifest" "namespace_argo_workflows" {
      [32m+[0m[0m manifest = {
          [32m+[0m[0m apiVersion = "v1"
          [32m+[0m[0m kind       = "Namespace"
          [32m+[0m[0m metadata   = {
              [32m+[0m[0m name = "argo"
            }
        }
      [32m+[0m[0m object   = {
          [32m+[0m[0m apiVersion = "v1"
          [32m+[0m[0m kind       = "Namespace"
          [32m+[0m[0m metadata   = {
              [32m+[0m[0m annotations                = (known after apply)
              [32m+[0m[0m creationTimestamp          = (known after apply)
              [32m+[0m[0m deletionGracePeriodSeconds = (known after apply)
              [32m+[0m[0m deletionTimestamp          = (known after apply)
              [32m+[0m[0m finalizers                 = (known after apply)
              [32m+[0m[0m generateName               = (known after apply)
              [32m+[0m[0m generation                 = (known after apply)
              [32m+[0m[0m labels                     = (known after apply)
              [32m+[0m[0m managedFields              = (known after apply)
              [32m+[0m[0m name                       = "argo"
              [32m+[0m[0m namespace                  = (known after apply)
              [32m+[0m[0m ownerReferences            = (known after apply)
              [32m+[0m[0m resourceVersion            = (known after apply)
              [32m+[0m[0m selfLink                   = (known after apply)
              [32m+[0m[0m uid                        = (known after apply)
            }
          [32m+[0m[0m spec       = {
              [32m+[0m[0m finalizers = (known after apply)
            }
        }
    }

[1m  # kubernetes_manifest.namespace_backstage[0m will be created
[0m  [32m+[0m[0m resource "kubernetes_manifest" "namespace_backstage" {
      [32m+[0m[0m manifest = {
          [32m+[0m[0m apiVersion = "v1"
          [32m+[0m[0m kind       = "Namespace"
          [32m+[0m[0m metadata   = {
              [32m+[0m[0m name = "backstage"
            }
        }
      [32m+[0m[0m object   = {
          [32m+[0m[0m apiVersion = "v1"
          [32m+[0m[0m kind       = "Namespace"
          [32m+[0m[0m metadata   = {
              [32m+[0m[0m annotations                = (known after apply)
              [32m+[0m[0m creationTimestamp          = (known after apply)
              [32m+[0m[0m deletionGracePeriodSeconds = (known after apply)
              [32m+[0m[0m deletionTimestamp          = (known after apply)
              [32m+[0m[0m finalizers                 = (known after apply)
              [32m+[0m[0m generateName               = (known after apply)
              [32m+[0m[0m generation                 = (known after apply)
              [32m+[0m[0m labels                     = (known after apply)
              [32m+[0m[0m managedFields              = (known after apply)
              [32m+[0m[0m name                       = "backstage"
              [32m+[0m[0m namespace                  = (known after apply)
              [32m+[0m[0m ownerReferences            = (known after apply)
              [32m+[0m[0m resourceVersion            = (known after apply)
              [32m+[0m[0m selfLink                   = (known after apply)
              [32m+[0m[0m uid                        = (known after apply)
            }
          [32m+[0m[0m spec       = {
              [32m+[0m[0m finalizers = (known after apply)
            }
        }
    }

[1m  # kubernetes_manifest.namespace_data_on_eks[0m will be created
[0m  [32m+[0m[0m resource "kubernetes_manifest" "namespace_data_on_eks" {
      [32m+[0m[0m manifest = {
          [32m+[0m[0m apiVersion = "v1"
          [32m+[0m[0m kind       = "Namespace"
          [32m+[0m[0m metadata   = {
              [32m+[0m[0m name = "data-on-eks"
            }
        }
      [32m+[0m[0m object   = {
          [32m+[0m[0m apiVersion = "v1"
          [32m+[0m[0m kind       = "Namespace"
          [32m+[0m[0m metadata   = {
              [32m+[0m[0m annotations                = (known after apply)
              [32m+[0m[0m creationTimestamp          = (known after apply)
              [32m+[0m[0m deletionGracePeriodSeconds = (known after apply)
              [32m+[0m[0m deletionTimestamp          = (known after apply)
              [32m+[0m[0m finalizers                 = (known after apply)
              [32m+[0m[0m generateName               = (known after apply)
              [32m+[0m[0m generation                 = (known after apply)
              [32m+[0m[0m labels                     = (known after apply)
              [32m+[0m[0m managedFields              = (known after apply)
              [32m+[0m[0m name                       = "data-on-eks"
              [32m+[0m[0m namespace                  = (known after apply)
              [32m+[0m[0m ownerReferences            = (known after apply)
              [32m+[0m[0m resourceVersion            = (known after apply)
              [32m+[0m[0m selfLink                   = (known after apply)
              [32m+[0m[0m uid                        = (known after apply)
            }
          [32m+[0m[0m spec       = {
              [32m+[0m[0m finalizers = (known after apply)
            }
        }
    }

[1m  # kubernetes_manifest.secret_backstage_postgresql_config[0m will be created
[0m  [32m+[0m[0m resource "kubernetes_manifest" "secret_backstage_postgresql_config" {
      [32m+[0m[0m manifest = {
          [32m+[0m[0m apiVersion = "v1"
          [32m+[0m[0m data       = {
              [32m+[0m[0m POSTGRES_DB       = "YmFja3N0YWdl"
              [32m+[0m[0m POSTGRES_PASSWORD = (sensitive value)
              [32m+[0m[0m POSTGRES_USER     = "YmFja3N0YWdl"
            }
          [32m+[0m[0m kind       = "Secret"
          [32m+[0m[0m metadata   = {
              [32m+[0m[0m name      = "postgresql-config"
              [32m+[0m[0m namespace = "backstage"
            }
        }
      [32m+[0m[0m object   = {
          [32m+[0m[0m apiVersion = "v1"
          [32m+[0m[0m data       = {
              [32m+[0m[0m POSTGRES_DB       = "YmFja3N0YWdl"
              [32m+[0m[0m POSTGRES_PASSWORD = "WU9zMUZKNU05a3M5WVVuRU5GUERvYlVuYkZXcFJvdUxYTmRlbUpiZ3pVbnFCeUZD"
              [32m+[0m[0m POSTGRES_USER     = "YmFja3N0YWdl"
            }
          [32m+[0m[0m immutable  = (known after apply)
          [32m+[0m[0m kind       = "Secret"
          [32m+[0m[0m metadata   = {
              [32m+[0m[0m annotations                = (known after apply)
              [32m+[0m[0m creationTimestamp          = (known after apply)
              [32m+[0m[0m deletionGracePeriodSeconds = (known after apply)
              [32m+[0m[0m deletionTimestamp          = (known after apply)
              [32m+[0m[0m finalizers                 = (known after apply)
              [32m+[0m[0m generateName               = (known after apply)
              [32m+[0m[0m generation                 = (known after apply)
              [32m+[0m[0m labels                     = (known after apply)
              [32m+[0m[0m managedFields              = (known after apply)
              [32m+[0m[0m name                       = "postgresql-config"
              [32m+[0m[0m namespace                  = "backstage"
              [32m+[0m[0m ownerReferences            = (known after apply)
              [32m+[0m[0m resourceVersion            = (known after apply)
              [32m+[0m[0m selfLink                   = (known after apply)
              [32m+[0m[0m uid                        = (known after apply)
            }
          [32m+[0m[0m stringData = (known after apply)
          [32m+[0m[0m type       = (known after apply)
        }
    }

[1m  # kubernetes_manifest.serviceaccount_data_on_eks[0m will be created
[0m  [32m+[0m[0m resource "kubernetes_manifest" "serviceaccount_data_on_eks" {
      [32m+[0m[0m manifest = {
          [32m+[0m[0m apiVersion = "v1"
          [32m+[0m[0m kind       = "ServiceAccount"
          [32m+[0m[0m metadata   = {
              [32m+[0m[0m annotations = {
                  [32m+[0m[0m "eks.amazonaws.com/role-arn" = "arn:aws:iam::136658121779:role/cnoe-external-dns20240425135847192400000004"
                }
              [32m+[0m[0m labels      = {
                  [32m+[0m[0m app = "data-on-eks"
                }
              [32m+[0m[0m name        = "data-on-eks"
              [32m+[0m[0m namespace   = "data-on-eks"
            }
        }
      [32m+[0m[0m object   = {
          [32m+[0m[0m apiVersion                   = "v1"
          [32m+[0m[0m automountServiceAccountToken = (known after apply)
          [32m+[0m[0m imagePullSecrets             = (known after apply)
          [32m+[0m[0m kind                         = "ServiceAccount"
          [32m+[0m[0m metadata                     = {
              [32m+[0m[0m annotations                = (known after apply)
              [32m+[0m[0m creationTimestamp          = (known after apply)
              [32m+[0m[0m deletionGracePeriodSeconds = (known after apply)
              [32m+[0m[0m deletionTimestamp          = (known after apply)
              [32m+[0m[0m finalizers                 = (known after apply)
              [32m+[0m[0m generateName               = (known after apply)
              [32m+[0m[0m generation                 = (known after apply)
              [32m+[0m[0m labels                     = (known after apply)
              [32m+[0m[0m managedFields              = (known after apply)
              [32m+[0m[0m name                       = "data-on-eks"
              [32m+[0m[0m namespace                  = "data-on-eks"
              [32m+[0m[0m ownerReferences            = (known after apply)
              [32m+[0m[0m resourceVersion            = (known after apply)
              [32m+[0m[0m selfLink                   = (known after apply)
              [32m+[0m[0m uid                        = (known after apply)
            }
          [32m+[0m[0m secrets                      = (known after apply)
        }
    }

[1m  # terraform_data.argo_workflows_keycloak_setup[0m will be created
[0m  [32m+[0m[0m resource "terraform_data" "argo_workflows_keycloak_setup" {
      [32m+[0m[0m id = (known after apply)
    }

[1m  # terraform_data.backstage_keycloak_setup[0m will be created
[0m  [32m+[0m[0m resource "terraform_data" "backstage_keycloak_setup" {
      [32m+[0m[0m id = (known after apply)
    }

[1mPlan:[0m 17 to add, 3 to change, 1 to destroy.
[0m[90m
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m

Note: You didn't use the -out option to save this plan, so Terraform can't
guarantee to take exactly these actions if you run "terraform apply" now.
